# benchmark execution wrapper

basedir = $ENV(HOME)

executable = $(basedir)/bin/extract.sh
universe   = vanilla

# working dir will be set by condor_dagman
#initialdir = /path/to/run/logs

#input     = test.data # hm, stdin...

# output and error is hopefully empty
output     = extract_$(cluster)_$(process).out
error      = extract_$(cluster)_$(process).err

# condor log will be set by condor_dagman
#log =

notification = Error
notify_user = tkren@kr.tuwien.ac.at

requirements = machine == "lion.kr.tuwien.ac.at"

request_cpus = 1
request_memory = 512

#environment = 

# arguments will be set by condor_dagman
#
# DAG spliced nodes have the form JOB+NODE.  In our setting we set JOB
# to R/tTT/bBB/sSS/iIIII/rRR/NNN from which we can extract the information
# for building the arguments for our executable.
#
# 0 2   6   10  14    20   25
# R/t01/b01/s01/i0001/r000/000+STATS
#
thejob = $$([substr(""$(jobname)"",2,-10)])
arguments  = "$(basedir)/$(thejob) $(basedir)/$(thejob) $(basedir)/$(thejob)"

# number of runs
queue 1
